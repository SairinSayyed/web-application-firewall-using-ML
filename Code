# -*- coding: utf-8 -*-
"""Dataset1.ipynb
  Sairin Sayyed

Load the necessary libraries
"""

from sklearn.feature_extraction.text import TfidfVectorizer
import os
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import urllib.parse
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support
import seaborn as sns
import matplotlib.pyplot as plt

"""Function to load the data from the file"""

def loadFile(name):
    directory = str(os.getcwd())  # Get the current working directory
    filepath = os.path.join(directory, name)  # Create the file path
    with open(filepath, 'r') as f:
        data = f.readlines()  # Read the lines from the file
    data = list(set(data))  # Remove duplicates from the data
    result = []
    for d in data:
        d = str(urllib.parse.unquote(d))  # Convert URL-encoded data to a simple string
        result.append(d)
    return result

"""Load the malicious and clean query data"""

badQueries = loadFile('badqueries.txt')
validQueries = loadFile('goodqueries.txt')

"""Remove Duplicate from data """

badQueries = list(set(badQueries))
validQueries = list(set(validQueries))
allQueries = badQueries + validQueries # Combine the queries into a single list

"""Create labels for the queries (1 for malicious, 0 for clean)"""

yBad = [1 for i in range(0, len(badQueries))]  #labels, 1 for malicious and 0 for clean
yGood = [0 for i in range(0, len(validQueries))]
y = yBad + yGood
queries = allQueries

"""Convert the queries into vectors using TF-IDF vectorization"""

vectorizer = TfidfVectorizer(min_df = 0.0, analyzer="char", sublinear_tf=True, ngram_range=(1,3)) #converting data to vectors
X = vectorizer.fit_transform(queries)

"""Split the data into training and testing sets"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #splitting data

"""Calculate the count of malicious and clean queries"""

badCount = len(badQueries)
validCount = len(validQueries)

print( badCount)
print(validCount)

"""Train the logistic regression model"""

lgs = LogisticRegression(class_weight={1: 2 * validCount / badCount, 0: 1.0}) # class_weight='balanced')
lgs.fit(X_train, y_train) #training our model

"""Evaluation of the model"""

predicted = lgs.predict(X_test)
print(predicted)

"""Calculate and print evaluation metrics"""

fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))
auc = metrics.auc(fpr, tpr)

print("Accuracy of Logistic Regression Model: %f" % lgs.score(X_test, y_test))  #checking the accuracy
print("Precision of Logistic Regression Model: %f" % metrics.precision_score(y_test, predicted))
print("Recall of Logistic Regression Model: %f" % metrics.recall_score(y_test, predicted))
print("F1-Score of Logistic Regression Model: %f" % metrics.f1_score(y_test, predicted))
print("AUC of Logistic Regression Model: %f" % auc)

"""Print the classification report"""

print(classification_report(y_test, predicted))

"""Create and display the confusion matrix as a heatmap"""

cm=confusion_matrix(y_test, predicted)
f,ax=plt.subplots(figsize=(5,5))
sns.heatmap(cm,annot=True,linewidth=0.5,linecolor="red",fmt=".0f",ax=ax)
plt.xlabel("X_test")
plt.ylabel("y_test")
plt.show()

"""**Random Forest** **Classifier**

Load the necessary libraries
"""

from sklearn.feature_extraction.text import TfidfVectorizer
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
import urllib.parse
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support
import seaborn as sns
import matplotlib.pyplot as plt

"""Function to load the data from the file"""

def loadFile(name):
    directory = str(os.getcwd())  # Get the current working directory
    filepath = os.path.join(directory, name)  # Create the file path
    with open(filepath, 'r') as f:
        data = f.readlines()  # Read the lines from the file
    data = list(set(data))  # Remove duplicates from the data
    result = []
    for d in data:
        d = str(urllib.parse.unquote(d))  # Convert URL-encoded data to a simple string
        result.append(d)
    return result

"""Load the malicious and clean query data"""

badQueries = loadFile('badqueries.txt')
validQueries = loadFile('goodqueries.txt')

"""Remove Duplicate from data """

badQueries = list(set(badQueries))
validQueries = list(set(validQueries))
allQueries = badQueries + validQueries # Combine the queries into a single list

"""Create labels for the queries (1 for malicious, 0 for clean)"""

yBad = [1 for i in range(0, len(badQueries))]  #labels, 1 for malicious and 0 for clean
yGood = [0 for i in range(0, len(validQueries))]
y = yBad + yGood
queries = allQueries

"""Convert the queries into vectors using TF-IDF vectorization"""

vectorizer = TfidfVectorizer(min_df = 0.0, analyzer="char", sublinear_tf=True, ngram_range=(1,3)) #converting data to vectors
X = vectorizer.fit_transform(queries)

"""Split the data into training and testing sets"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #splitting data

"""Calculate the count of malicious and clean queries"""

badCount = len(badQueries)
validCount = len(validQueries)

print(badCount)
print(validCount)

"""Train the Random Forest Classifier model"""

rf = RandomForestClassifier(n_estimators=2, n_jobs=-1)
rf.fit(X_train, y_train)

"""Evaluation of the model"""

predicted = rf.predict(X_test)
print(predicted)

"""Calculate and print evaluation metrics"""

fpr, tpr, _ = metrics.roc_curve(y_test, (rf.predict_proba(X_test)[:, 1]))
auc = metrics.auc(fpr, tpr)

print("Accuracy of Random Forest Classifier Model: %f" % rf.score(X_test, y_test))  #checking the accuracy
print("Precision Random Forest Classifier Model: %f" % metrics.precision_score(y_test, predicted))
print("Recall Random Forest Classifier Model: %f" % metrics.recall_score(y_test, predicted))
print("F1-Score Random Forest Classifier Model: %f" % metrics.f1_score(y_test, predicted))
print("AUC Random Forest Classifier Model: %f" % auc)

"""Print the classification report"""

print(classification_report(y_test, predicted))

"""Create and display the confusion matrix as a heatmap"""

cm=confusion_matrix(y_test, predicted)
f,ax=plt.subplots(figsize=(5,5))
sns.heatmap(cm,annot=True,linewidth=0.5,linecolor="red",fmt=".0f",ax=ax)
plt.xlabel("X_test")
plt.ylabel("y_test")
plt.show()

"""Evaluate both models and choose the best one based on evaluation metrics"""

lgs_accuracy = lgs.score(X_test, y_test)
rf_accuracy = rf.score(X_test, y_test)

if lgs_accuracy > rf_accuracy:
    best_model = lgs
else:
    best_model = rf

print(best_model)

"""Using Logistuc Regression Model to Predict the Query"""

# New queries to predict
newQueries = ["' OR '1", "hello"]

# Convert new queries to vectors
X_new = vectorizer.transform(newQueries)

# Use the best trained model to predict classes for new queries
predictions = best_model.predict(X_new)

# Print predictions
for query, prediction in zip(newQueries, predictions):
    if prediction == 1:
        print(f"{query}: Malicious")
    else:
        print(f"{query}: Clean")
